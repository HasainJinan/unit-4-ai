{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Code Hidden\n",
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 8.33Git/s]                                                     \n",
      "Fetching encoder.json: 1.05Mit [00:02, 372kit/s]                                                    \n",
      "Fetching hparams.json: 1.05Mit [00:00, 9.20Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [22:35, 367kit/s]                                   \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 1.37Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:01, 929kit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 1.06Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "#Download Code Hidden\n",
    "#gpt2.download_gpt2(\n",
    "#    model_name = \"124M\"\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "#Session Hidden\n",
    "session = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(session, model_name=\"124M\", reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's raining cats and iphones that night, she says. It's raining dogs and cats that night. It's raining cats and iphones that night.\n",
      "\n",
      "\"I'm so sorry. I can't put on my best shoes. I don't know why. But I am so sorry,\" she says, then bends over to shake her head. \"I'm so sorry. I'm so sorry for you. You're a good person. I love you. I really do.\"\n",
      "\n",
      "\"It's not easy for someone to have to explain themselves,\" she says forcefully. \"They have to learn how to deal with themselves, and they're still going to have to learn how to be good people. The public doesn't understand that. But then I will learn how to deal with my parents. I will learn how to deal with my children.\"\n",
      "\n",
      "The other woman is sobbing. She's trying to get out of bed. She's trying to explain to her friends. She's trying to get out of the car. She's trying to get to the doctor. She's trying to get to the hospital.\n",
      "\n",
      "\"I'm so sorry,\" she says. \"I can't do it.\"\n",
      "\n",
      "\"But you're a good person,\" he replies. \"I'm sorry.\"\n",
      "\n",
      "\"I'm not a bad person,\" she says.\n",
      "\n",
      "\"But then I will learn how to deal with my parents,\" he replies.\n",
      "\n",
      "\"And then I will be so happy for you,\" she says.\n",
      "\n",
      "\"I'm so sorry,\" he says.\n",
      "\n",
      "\"I beat myself up, like I said. I beat myself up, like I said. I'm so sorry for you. You're a good person. I love you. I really do.\"\n",
      "\n",
      "\"A good person,\" he says.\n",
      "\n",
      "\"And then I will be so happy for you,\" she says. \"And then I will be so happy for you.\"\n",
      "\n",
      "\"But then I will be so happy for you,\" he says.\n",
      "\n",
      "\"A good person,\" she says.\n",
      "\n",
      "\"And then I will be so happy for you,\" he says.\n",
      "\n",
      "After the doctor visits, we drive to another apartment in East Delhi, where the adults are moving in. We talk about how to properly treat our own children and how to raise our children properly.\n",
      "\n",
      "We have my own apartment.\n",
      "\n",
      "I've had to turn down almost every chance I get to live in this small apartment, which is about 12 square feet and has a nice lot of stuff. I'm not sure why. It's my move. I've had to turn down almost every chance I get to live in this small apartment, which is about 12 square feet and has a nice lot of stuff. I'm not sure why. It's my move.\n",
      "\n",
      "I've had to turn down almost every chance I get to live in this small apartment, which is about 12 square feet and has a nice lot of stuff. I'm not sure why. It's my move.\n",
      "\n",
      "I don't know why I'm not in this apartment. I'm not sure why I'm not in this apartment. I'm not sure why I'm not in this apartment. I'm not sure why I'm not in this apartment. I'm not sure why I'm not in this apartment. I'm not sure why I'm not in this apartment. I'm not sure why I'm not in this apartment. I'm not sure why I'm not in this apartment. I'm not sure why I'm not in this apartment.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do this.\n",
      "\n",
      "I can't do\n"
     ]
    }
   ],
   "source": [
    "#Generate\n",
    "gpt2.generate(session, model_name=\"124M\", prefix=\"It's raining cats and \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Session2 Hidden\n",
    "session2 = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732547121.608099 2788145 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 338025 tokens\n",
      "Training...\n",
      "[1 | 21.87] loss=3.99 avg=3.99\n",
      "[2 | 42.27] loss=3.87 avg=3.93\n",
      "[3 | 63.68] loss=3.83 avg=3.90\n",
      "[4 | 84.51] loss=3.62 avg=3.83\n",
      "[5 | 104.42] loss=3.52 avg=3.76\n",
      "[6 | 124.35] loss=3.69 avg=3.75\n",
      "[7 | 144.43] loss=3.74 avg=3.75\n",
      "[8 | 165.46] loss=3.62 avg=3.73\n",
      "[9 | 184.51] loss=3.64 avg=3.72\n",
      "[10 | 204.04] loss=3.75 avg=3.72\n",
      "[11 | 223.50] loss=3.44 avg=3.70\n",
      "[12 | 242.80] loss=3.76 avg=3.70\n",
      "[13 | 262.97] loss=3.75 avg=3.71\n",
      "[14 | 280.55] loss=3.29 avg=3.67\n",
      "[15 | 299.77] loss=3.54 avg=3.67\n",
      "[16 | 318.67] loss=3.59 avg=3.66\n",
      "[17 | 335.64] loss=3.56 avg=3.65\n",
      "[18 | 352.05] loss=3.42 avg=3.64\n",
      "[19 | 370.19] loss=3.58 avg=3.64\n",
      "[20 | 389.20] loss=3.74 avg=3.64\n",
      "[21 | 407.44] loss=3.36 avg=3.63\n",
      "[22 | 425.93] loss=3.40 avg=3.62\n",
      "[23 | 443.14] loss=3.75 avg=3.62\n",
      "[24 | 461.86] loss=3.24 avg=3.60\n",
      "[25 | 480.08] loss=3.46 avg=3.60\n",
      "[26 | 497.89] loss=3.37 avg=3.59\n",
      "[27 | 515.82] loss=3.45 avg=3.58\n",
      "[28 | 532.56] loss=3.26 avg=3.57\n",
      "[29 | 550.35] loss=3.54 avg=3.57\n",
      "[30 | 568.44] loss=3.39 avg=3.56\n",
      "[31 | 586.34] loss=3.44 avg=3.56\n",
      "[32 | 604.49] loss=3.07 avg=3.54\n",
      "[33 | 622.82] loss=3.27 avg=3.53\n",
      "[34 | 642.72] loss=3.44 avg=3.53\n",
      "[35 | 661.87] loss=3.34 avg=3.52\n",
      "[36 | 680.70] loss=3.27 avg=3.51\n",
      "[37 | 699.15] loss=3.09 avg=3.50\n",
      "[38 | 717.89] loss=3.49 avg=3.50\n",
      "[39 | 740.75] loss=3.13 avg=3.49\n",
      "[40 | 760.72] loss=3.44 avg=3.49\n",
      "[41 | 778.82] loss=3.48 avg=3.49\n",
      "[42 | 799.67] loss=3.00 avg=3.47\n",
      "[43 | 823.87] loss=3.39 avg=3.47\n",
      "[44 | 845.19] loss=3.49 avg=3.47\n",
      "[45 | 869.97] loss=3.68 avg=3.48\n",
      "[46 | 893.01] loss=3.22 avg=3.47\n",
      "[47 | 919.28] loss=3.17 avg=3.46\n",
      "[48 | 940.01] loss=3.32 avg=3.46\n",
      "[49 | 959.16] loss=3.36 avg=3.45\n",
      "[50 | 977.25] loss=3.53 avg=3.46\n",
      "[51 | 996.01] loss=3.19 avg=3.45\n",
      "[52 | 1014.12] loss=3.40 avg=3.45\n",
      "[53 | 1032.07] loss=3.31 avg=3.45\n",
      "[54 | 1050.03] loss=3.37 avg=3.44\n",
      "[55 | 1067.14] loss=3.31 avg=3.44\n",
      "[56 | 1085.43] loss=3.39 avg=3.44\n",
      "[57 | 1104.10] loss=3.36 avg=3.44\n",
      "[58 | 1121.15] loss=3.32 avg=3.43\n",
      "[59 | 1138.85] loss=3.55 avg=3.44\n",
      "[60 | 1157.51] loss=3.21 avg=3.43\n",
      "[61 | 1177.11] loss=3.41 avg=3.43\n",
      "[62 | 1196.00] loss=3.33 avg=3.43\n",
      "[63 | 1216.62] loss=3.23 avg=3.43\n",
      "[64 | 1236.80] loss=3.13 avg=3.42\n",
      "[65 | 1257.42] loss=3.34 avg=3.42\n",
      "[66 | 1278.22] loss=3.37 avg=3.42\n",
      "[67 | 1298.16] loss=3.40 avg=3.42\n",
      "[68 | 1317.77] loss=3.59 avg=3.42\n",
      "[69 | 1337.57] loss=3.32 avg=3.42\n",
      "[70 | 1357.42] loss=3.18 avg=3.41\n",
      "[71 | 1377.20] loss=3.22 avg=3.41\n",
      "[72 | 1396.47] loss=3.33 avg=3.41\n",
      "[73 | 1415.68] loss=3.17 avg=3.40\n",
      "[74 | 1435.45] loss=3.33 avg=3.40\n",
      "[75 | 1457.32] loss=3.12 avg=3.40\n",
      "[76 | 1479.13] loss=3.23 avg=3.39\n",
      "[77 | 1500.01] loss=3.02 avg=3.39\n",
      "[78 | 1521.42] loss=3.25 avg=3.38\n",
      "[79 | 1542.34] loss=3.19 avg=3.38\n",
      "[80 | 1563.16] loss=3.36 avg=3.38\n",
      "[81 | 1583.97] loss=3.24 avg=3.38\n",
      "[82 | 1603.05] loss=3.08 avg=3.37\n",
      "[83 | 1622.22] loss=3.07 avg=3.37\n",
      "[84 | 1642.37] loss=3.40 avg=3.37\n",
      "[85 | 1663.36] loss=3.11 avg=3.36\n",
      "[86 | 1683.75] loss=3.20 avg=3.36\n",
      "[87 | 1704.37] loss=3.31 avg=3.36\n",
      "[88 | 1724.24] loss=3.46 avg=3.36\n",
      "[89 | 1744.27] loss=3.08 avg=3.36\n",
      "[90 | 1765.48] loss=3.21 avg=3.35\n",
      "[91 | 1786.30] loss=3.12 avg=3.35\n",
      "[92 | 1806.78] loss=3.38 avg=3.35\n",
      "[93 | 1827.01] loss=3.23 avg=3.35\n",
      "[94 | 1846.74] loss=3.29 avg=3.35\n",
      "[95 | 1867.19] loss=3.22 avg=3.35\n",
      "[96 | 1887.19] loss=3.19 avg=3.34\n",
      "[97 | 1907.10] loss=3.12 avg=3.34\n",
      "[98 | 1925.52] loss=3.33 avg=3.34\n",
      "[99 | 1943.62] loss=2.96 avg=3.33\n",
      "[100 | 1961.92] loss=3.30 avg=3.33\n",
      "Saving checkpoint/shakespeare/model-100\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "gpt2.finetune(\n",
    "    session2,\n",
    "    \"shakespeare.txt\",\n",
    "    model_name = \"124M\",\n",
    "    steps = 100,\n",
    "    run_name = \"shakespeare\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasain: Now dawns thy reckoning, and thy gore shall glisten before the temples of man.\n",
      "\n",
      "TRANIO:\n",
      "O, a stag! at thy knee!\n",
      "\n",
      "LUCENTIO:\n",
      "Ay, sir, a man; but how, thou art not yet a man?\n",
      "\n",
      "TRANIO:\n",
      "O, a man!\n",
      "\n",
      "LUCENTIO:\n",
      "O, a stag!\n",
      "\n",
      "TRANIO:\n",
      "\n",
      "LUCENTIO:\n",
      "A man, sir!\n",
      "\n",
      "TRANIO:\n",
      "O, a stag!\n",
      "\n",
      "TRANIO:\n",
      "A man, sir!\n",
      "\n",
      "LUCENTIO:\n",
      "Ay, sir!\n",
      "\n",
      "TRANIO:\n",
      "Now, let the dance begin.\n",
      "\n",
      "LUCENTIO:\n",
      "Here's a woman;\n",
      "She's a stag!\n",
      "\n",
      "TRANIO:\n",
      "Here's a woman;\n",
      "Nay, her name is 'Loser'\n",
      "And, seeing she's a man,\n",
      "She'll dance with thee.\n",
      "\n",
      "LUCENTIO:\n",
      "Why, then she's a man: a man\n",
      "Who, I think, is a beast.\n",
      "\n",
      "TRANIO:\n",
      "A man, sir!\n",
      "\n",
      "LUCENTIO:\n",
      "And now, sir!\n",
      "\n",
      "TRANIO:\n",
      "A man, sir!\n",
      "\n",
      "LUCENTIO:\n",
      "A man, sir!\n",
      "\n",
      "TRANIO:\n",
      "A man, sir!\n",
      "\n",
      "LUCENTIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "LUCENTIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "LUCENTIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "LUCENTIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "LUCENTIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "LUCENTIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "LUCENTIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n",
      "TRANIO:\n",
      "A man!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "    session2,\n",
    "    prefix = \"Hasain: Now dawns thy reckoning, and thy gore shall glisten before the temples of man.\",\n",
    "    run_name = \"shakespeare\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
