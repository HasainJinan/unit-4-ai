{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Code Hidden\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             file_path   label\n",
      "0       flower_photos/roses/16209331331_343c899d38.jpg   roses\n",
      "1        flower_photos/roses/5777669976_a205f61e5b.jpg   roses\n",
      "2      flower_photos/roses/4860145119_b1c3cbaa4e_n.jpg   roses\n",
      "3       flower_photos/roses/15011625580_7974c44bce.jpg   roses\n",
      "4     flower_photos/roses/17953368844_be3d18cf30_m.jpg   roses\n",
      "...                                                ...     ...\n",
      "3665     flower_photos/tulips/134143359_71fa8dd9a4.jpg  tulips\n",
      "3666    flower_photos/tulips/3637371174_a8dfcc1b35.jpg  tulips\n",
      "3667  flower_photos/tulips/6948239566_0ac0a124ee_n.jpg  tulips\n",
      "3668    flower_photos/tulips/2834890466_1cf220fba1.jpg  tulips\n",
      "3669   flower_photos/tulips/13953090784_0c7d7a904e.jpg  tulips\n",
      "\n",
      "[3670 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Code Hidden\n",
    "data = []\n",
    "for dir, x, files in os.walk(\"flower_photos\"):\n",
    "    label = dir.split(\"/\")[-1]\n",
    "    for file in files:\n",
    "        path = os.path.join(dir, file)\n",
    "        data.append([path, label])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"file_path\", \"label\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Hidden\n",
    "datagen = ImageDataGenerator(\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2936 validated image filenames belonging to 5 classes.\n",
      "Found 734 validated image filenames belonging to 5 classes.\n",
      "dict_items([('daisy', 0), ('dandelion', 1), ('roses', 2), ('sunflowers', 3), ('tulips', 4)])\n"
     ]
    }
   ],
   "source": [
    "#Code Hidden\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    x_col = \"file_path\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (224, 224),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True,\n",
    "    subset = \"training\"\n",
    ")\n",
    "\n",
    "valid_gen = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    x_col = \"file_path\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (224, 224),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True,\n",
    "    subset = \"validation\"\n",
    ")\n",
    "\n",
    "print(train_gen.class_indices.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Hidden\n",
    "base_model = EfficientNetB3(\n",
    "    include_top= False, \n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3), \n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(rate=.45, seed=123),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    Adamax(learning_rate= .0001), \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'acc', \n",
    "        tf.keras.metrics.Precision(), \n",
    "        tf.keras.metrics.Recall(), \n",
    "        tf.keras.metrics.AUC()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Hidden\n",
    "early_stopping = EarlyStopping(\n",
    "    patience = 10,\n",
    "    min_delta = 0,\n",
    "    monitor = \"val_loss\",\n",
    "    verbose = 0,\n",
    "    restore_best_weights = True,\n",
    "    baseline = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - acc: 0.4208 - auc_2: 0.7125 - loss: 1.7108 - precision_2: 0.4680 - recall_2: 0.3403 - val_acc: 0.1431 - val_auc_2: 0.4436 - val_loss: 2.7207 - val_precision_2: 0.1502 - val_recall_2: 0.1035\n",
      "Epoch 2/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 3s/step - acc: 0.7577 - auc_2: 0.9395 - loss: 0.6912 - precision_2: 0.8199 - recall_2: 0.6967 - val_acc: 0.1158 - val_auc_2: 0.3987 - val_loss: 3.7497 - val_precision_2: 0.1244 - val_recall_2: 0.1076\n",
      "Epoch 3/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 4s/step - acc: 0.8215 - auc_2: 0.9672 - loss: 0.5032 - precision_2: 0.8614 - recall_2: 0.7841 - val_acc: 0.1172 - val_auc_2: 0.3757 - val_loss: 4.4415 - val_precision_2: 0.1235 - val_recall_2: 0.1117\n",
      "Epoch 4/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 3s/step - acc: 0.8815 - auc_2: 0.9824 - loss: 0.3585 - precision_2: 0.9109 - recall_2: 0.8508 - val_acc: 0.1185 - val_auc_2: 0.3668 - val_loss: 4.9834 - val_precision_2: 0.1265 - val_recall_2: 0.1172\n",
      "Epoch 5/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 4s/step - acc: 0.9011 - auc_2: 0.9883 - loss: 0.2915 - precision_2: 0.9220 - recall_2: 0.8767 - val_acc: 0.1172 - val_auc_2: 0.3620 - val_loss: 5.3476 - val_precision_2: 0.1245 - val_recall_2: 0.1172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x294148430>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AI Training Code Hidden\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data = valid_gen,\n",
    "    epochs = 5,\n",
    "    validation_steps = None,\n",
    "    shuffle = False,\n",
    "    callbacks = early_stopping,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Code Hidden\n",
    "model.save(\"flowers.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x302dd24d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "dict_items([('daisy', 0), ('dandelion', 1), ('roses', 2), ('sunflowers', 3), ('tulips', 4)])\n",
      "Index:  0\n"
     ]
    }
   ],
   "source": [
    "#Code Hidden\n",
    "import cv2\n",
    "from tensorflow.keras.saving import load_model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = load_model(\"flowers.keras\")\n",
    "\n",
    "input_image = cv2.imread(\"flower_photos/tulips/10686568196_b1915544a8.jpg\")\n",
    "input_image_resize = cv2.resize(input_image, (224,224))\n",
    "\n",
    "input_image_scaled = input_image_resize/255\n",
    "image_reshaped = np.reshape(input_image_scaled, [1, 224, 224, 3])\n",
    "\n",
    "input_prediction = model.predict(image_reshaped)\n",
    "print(train_gen.class_indices.items())\n",
    "print(\"Index: \", np.argmax(input_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
